{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-dimensional Gaussian process datasets 2\n",
    "\n",
    "Fewer datasets, but more different numbers of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0227-165745/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_raw = pd.read_feather(\"measures.feather\")\n",
    "\n",
    "if \"error\" in ms_raw.columns:\n",
    "    print(\"Errors:\", len(ms_raw[~ms_raw[\"error\"].isnull()]))\n",
    "    ms_raw = ms_raw.loc[ms_raw[\"error\"].isnull()]\n",
    "\n",
    "ms_raw = smooth.analysis.expand_dataset_columns(ms_raw)\n",
    "ms = ms_raw\n",
    "\n",
    "# divergent_model_mask = (ms[\"loss\"] == np.inf) | (~(ms[\"train_loss\"] < 0.1))\n",
    "# print(\"Divergent models:\", len(ms[divergent_model_mask]))\n",
    "# ms = ms.loc[~divergent_model_mask]\n",
    "\n",
    "print(\"Remaining:\", len(ms))\n",
    "smooth.analysis.remove_constant_columns(ms, verbose=True)\n",
    "# ms = smooth.analysis.expand_dataset_columns(ms)\n",
    "ms.loc[:,\"log_dir\"] = ms[\"log_dir\"].str.split(\"/\").str.get(-1)\n",
    "\n",
    "ms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms[\"hidden_size\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ms.columns:\n",
    "    if ms[col].nunique() <= 20:\n",
    "        sns.countplot(ms[col])\n",
    "        plt.show()\n",
    "\n",
    "# plt.hist(ms[\"dim\"].astype(str))\n",
    "# plt.bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"actual_epochs\", \"train_loss\", \"test_loss\"]\n",
    "cols = ms.columns\n",
    "\n",
    "trim = 0.1\n",
    "\n",
    "for col in cols:\n",
    "    if ms[col].dtype == \"object\":\n",
    "        continue\n",
    "    \n",
    "    data = ms.loc[(ms[col] >= ms[col].quantile(trim/2)) & (ms[col] <= ms[col].quantile(1-trim/2)), col]\n",
    "    \n",
    "    plt.hist(data, bins=20)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_path_length_f(dataset_name):\n",
    "    dataset = smooth.datasets.from_name(dataset_name)\n",
    "    n = len(dataset.x_test)\n",
    "    y = sorted(dataset.y_test.reshape((-1,)))\n",
    "#     cs = np.cumsum(y)[::-1]\n",
    "#     res = 0\n",
    "#     for i in range(n - 1):\n",
    "#         res += cs[i] - y[i] * (n - i)\n",
    "\n",
    "#     return res / (n ** 2)\n",
    "    res = 0\n",
    "    for a in y:\n",
    "        for b in y:\n",
    "            res += np.abs(a - b)\n",
    "    return res / (n ** 2)\n",
    "\n",
    "optimal_lengths = {}\n",
    "for seed in tqdm.notebook.tqdm(range(1, 6)):\n",
    "    optimal_lengths[seed] = get_optimal_path_length_f(\"gp-100-{}-1.0-77\".format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1 = ms\n",
    "measure_cols = [\"gradient_norm\", \"path_length_d\", \"path_length_f\"]\n",
    "for measure in measure_cols + [\"l2\"]:\n",
    "#     ax = plt.subplot()\n",
    "#     ms1.loc[:,\"hidden_size_s\"] = ms1[\"hidden_size\"].astype(str) + \" units\"\n",
    "    sns.relplot(\n",
    "        data=ms1,\n",
    "        x=\"samples_train\",\n",
    "        y=measure,\n",
    "        hue=\"hidden_size\",\n",
    "#         col=\"batch_size\",\n",
    "        kind=\"line\",\n",
    "#                 ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in measure_cols:\n",
    "    n_bins = 10\n",
    "    bins = np.logspace(-2, 2, 20)\n",
    "    plt.hist(ratios[measure], bins=np.linspace(-2, 2, 30))\n",
    "#     plt.xscale(\"log\")\n",
    "    plt.title(\"log ratio of {}\".format(measure))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Percentage of cases where ratio < 1: {:.1f}%\".format(\n",
    "        (ratios[measure] < np.log10(1)).sum() / len(ratios) * 100\n",
    "    ))\n",
    "    print(\"Percentage of cases where ratio < 1.5: {:.1f}%\".format(\n",
    "        (ratios[measure] < np.log10(1.5)).sum() / len(ratios) * 100\n",
    "    ))\n",
    "    print(\"90th percentile: ratio is {:.2f}\".format(\n",
    "        10 ** ratios[measure].quantile(0.9)\n",
    "#         (ratios[measure] < np.log(1.5)).sum() / len(ratios) * 100\n",
    "    ))\n",
    "#     print(np.sum(ratios[measure]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(np.log10(10), np.log10(1000), 10).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
