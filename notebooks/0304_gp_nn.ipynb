{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-smooth NNs on GP datasets\n",
    "\n",
    "Can we set hyperparameters such that the learned function is not smooth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0304_gp_nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of shallow relu neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn = pd.read_feather(\"measures.feather\")\n",
    "ms_nn = smooth.analysis.expand_dataset_columns(ms_nn)\n",
    "smooth.analysis.remove_constant_columns(ms_nn, verbose=True)\n",
    "print(len(ms_nn))\n",
    "ms_nn = ms_nn.loc[np.isfinite(ms_nn[\"path_length_f\"])]\n",
    "print(len(ms_nn))\n",
    "ms_nn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of the original GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp = pd.read_feather(\"measures_gp.feather\")\n",
    "ms_gp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized measures - divided by the corresponding measure of GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df1, df2, join_col, cols):\n",
    "    assert set(cols + [join_col]).issubset(set(df1.columns))\n",
    "    df = pd.merge(df1, df2[cols + [join_col]], on=join_col, suffixes=(\"\", \"_0\"))\n",
    "    for col in cols:\n",
    "        df[col + \"_n\"] = df[col] / df[col + \"_0\"]\n",
    "        del df[col + \"_0\"]\n",
    "    return df\n",
    "\n",
    "measure_cols = [\"train_loss\", \"test_loss\", \"path_length_f\"]\n",
    "ms_kr = normalize(ms_kr, ms_gp, \"dataset\", measure_cols)\n",
    "ms_nn = normalize(ms_nn, ms_gp, \"dataset\", measure_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn.loc[(ms_nn[\"dim\"] == 8) & (ms_nn[\"init_scale\"] == 10.) & ()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn[\"learning_params\"] = ms_nn[\"init_scale\"].map(str) + \",\" + ms_nn[\"learning_rate\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return\n",
    "ms_gp = smooth.analysis.get_gp_measures(ms_nn[\"dataset\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp2 = smooth.analysis.get_gp_measures(ms_nn[\"dataset\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normalized_cols(ms):\n",
    "    ms[\"plc\"] = ms[\"path_length_f\"] / ms[\"path_length_f_bound\"]\n",
    "    ms[\"plct\"] = ms[\"path_length_f_train\"] / ms[\"path_length_f_train_bound\"]\n",
    "    return ms\n",
    "\n",
    "add_normalized_cols(ms_gp)\n",
    "add_normalized_cols(ms_gp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.relplot(data=ms_gp2, x=\"dim\", y=\"test_loss\", hue=\"samples_train\")\n",
    "ax = grid.axes[0][0]\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1 = ms\n",
    "measure_cols = [\"train_loss\", \"test_loss\", \"path_length_f\", \"path_length_d\", \"weights_rms\"]\n",
    "# measure_cols = [\"path_length_f\"]\n",
    "\n",
    "for measure in measure_cols:\n",
    "# for dim in sorted(ms_nn[\"dim\"].unique()):\n",
    "    IPython.display.display(IPython.display.Markdown(\"### dim = {}\".format(dim)))\n",
    "    if True:\n",
    "#         ms1 = ms_nn[(ms_nn[\"dim\"] == dim) & (ms_nn[\"hidden_size\"] == 64)]\n",
    "        ms1 = ms_nn[(ms_nn[\"hidden_size\"] == 64)]\n",
    "        grid = sns.relplot(\n",
    "            data=ms1,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"init_scale\",\n",
    "            style=\"learning_rate\",\n",
    "            col=\"dim\",\n",
    "            col_wrap=3,\n",
    "            kind=\"line\",\n",
    "            palette=smooth.analysis.make_palette(ms1[\"init_scale\"].unique()),\n",
    "    #                 ax=ax\n",
    "        )\n",
    "        ax = grid.axes[0] #[0]\n",
    "\n",
    "#         if measure == \"path_length_f\":\n",
    "#             ol = optimal_lengths[\"gp-{}-{}-1.0\".format(dim, seed)]\n",
    "#             plt.plot([ms1[\"samples_train\"].min(), ms1[\"samples_train\"].max()], [ol, ol])\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        if \"loss\" in measure or True:\n",
    "            ax.set_yscale(\"log\")\n",
    "#         plt.title(\"dim={}\".format(dim))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_bound = (ms_gp\n",
    "    .drop(columns=[\"path_length_f\", \"path_length_f_train\", \"train_loss\", \"test_loss\"])\n",
    "    .rename(columns={\n",
    "        \"path_length_f_bound\": \"path_length_f\",\n",
    "        \"path_length_f_train_bound\": \"path_length_f_train\",\n",
    "    })\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(groups, filter_f: None):\n",
    "    filter_f = filter_f or (lambda df: df)\n",
    "    l = []\n",
    "    for group_name, group in groups:\n",
    "        for name, ms_cur in group:\n",
    "            ms_cur = ms_cur.copy()\n",
    "            ms_cur.loc[:, \"source\"] = name\n",
    "            ms_cur.loc[:, \"group\"] = group_name\n",
    "            l.append(ms_cur)\n",
    "\n",
    "    ms_all = pd.concat(l, sort=False)\n",
    "    ms_all = filter_f(ms_all)\n",
    "    ms_all = ms_all.loc[\n",
    "        (ms_all[\"dim\"] == dim)\n",
    "#         & (ms_all[\"seed\"] == 1)\n",
    "        & (ms_all[\"lengthscale\"] == ms_all[\"dim\"])\n",
    "    ]\n",
    "    \n",
    "    for measure in [\"train_loss\", \"test_loss\", \"path_length_f\", \"path_length_f_train\"]:\n",
    "        grid = sns.relplot(\n",
    "            data=ms_all,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"source\",\n",
    "            col=\"group\",\n",
    "            kind=\"line\",\n",
    "        )\n",
    "        ax = grid.axes[0][0]\n",
    "        ax.set_xscale(\"log\")\n",
    "        if measure in [\"train_loss\", \"test_loss\",\n",
    "                      \"path_length_f\"\n",
    "                      ]:\n",
    "            ax.set_yscale(\"log\")\n",
    "#         if measure in [\"path_length_f\"]:\n",
    "#             ax.set_ylim(0.03, 30)\n",
    "        plt.show()\n",
    "\n",
    "nn_group = []\n",
    "for init in sorted(ms_nn[\"init_scale\"].unique()):\n",
    "    nn_group.append((\n",
    "        \"nn, is={:02}\".format(init),\n",
    "        ms_nn.loc[(ms_nn[\"hidden_size\"] == 64) & (ms_nn[\"init_scale\"] == init) & (ms_nn[\"learning_rate\"] == 0.01)],\n",
    "    ))\n",
    "nn_group.append((\"gp_noise\", ms_gp))\n",
    "nn_group.append((\"gp_noiseless\", ms_gp2))\n",
    "nn_group.append((\"bound\", ms_bound))\n",
    "\n",
    "def filter_f(ms):\n",
    "    return ms.loc[\n",
    "        (ms[\"dim\"] == dim)\n",
    "#         & (ms_all[\"seed\"] == 1)\n",
    "        & (ms[\"lengthscale\"] == ms[\"dim\"])\n",
    "    ]\n",
    "\n",
    "for dim in sorted(ms_nn[\"dim\"].unique()):\n",
    "    display(IPython.display.Markdown(\"### dim = {}\".format(dim)))\n",
    "    plot_compare([(\"nn\", nn_group)], filter_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = smooth.datasets.from_params(**dict(name=\"gp\", dim=16, lengthscale=16., seed=123, samples_train=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = [0., 1., 2.]\n",
    "# y = np.random.randn(6)\n",
    "y = [0., 3., 2.]\n",
    "dataset = smooth.datasets.Dataset(y,y,[],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smooth.measures.path_length_f_lower_bound(dataset, use_test_set=False))\n",
    "\n",
    "y = dataset.y_train\n",
    "act = 0\n",
    "for y1 in y:\n",
    "    for y2 in y:\n",
    "        act += np.abs(y1 - y2)\n",
    "\n",
    "print(act / (len(y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = smooth.datasets.from_name(\"gp-2-1-1.0-100-0-0\")\n",
    "dataset2 = smooth.datasets.from_name(\"gp-2-1-1.0-100-0-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.x_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset1.x_train[:10])\n",
    "print(dataset2.x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./bs=64_d=gp-128-1-128.0-1000_e=100000_hs=16_is=0.1_i=0_lr=0.001/model.h5\")\n",
    "dataset = smooth.datasets.from_name(\"gp-128-1-128.0-1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = smooth.measures.get_measures(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(a=1, b=2)\n",
    "a.update({\"c\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in model.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
