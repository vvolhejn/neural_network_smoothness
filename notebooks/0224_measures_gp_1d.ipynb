{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First results with 1D Gaussian process datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "sys.path.append(\"/nfs/scistore12/chlgrp/vvolhejn/smooth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = smooth.datasets.GaussianProcessDataset(\n",
    "#     x_min=-1, x_max=1,\n",
    "#     samples_train=50, samples_test=200,\n",
    "# #     seed=123,\n",
    "#     plot=True,\n",
    "# )\n",
    "\n",
    "dataset = smooth.datasets.GaussianProcessDataset(\n",
    "    samples_train=100,\n",
    "    lengthscale=0.3,\n",
    "    plot=True,\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_history_cb = smooth.callbacks.WeightsHistoryCallback(min_snapshots=200)\n",
    "_model = smooth.model.train_shallow(\n",
    "    dataset,\n",
    "    learning_rate=0.03,\n",
    "    init_scale=10.,\n",
    "    epochs=100000,\n",
    "    hidden_size=500,\n",
    "    batch_size=len(dataset.x_train),\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\"loss\", min_delta=1e-5, patience=2000),\n",
    "        smooth.callbacks.Tqdm(verbose=0),\n",
    "        tf.keras.callbacks.TerminateOnNaN(),\n",
    "        _history_cb\n",
    "    ],\n",
    "    train_val_split=1.0,\n",
    "    activation=\"relu\",\n",
    ")\n",
    "smooth.analysis.plot_shallow(_model, dataset)\n",
    "_ani = smooth.analysis.plot_shallow(_model, dataset, weights_history=_history_cb.weights_history)\n",
    "display(HTML(_ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset.x_train, dataset.y_train, color=\"g\")\n",
    "x = np.linspace(-1, 1, 100)\n",
    "plt.plot(x, _model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ow = _model.get_weights()\n",
    "_model.set_weights(_history_cb.weights_history[max(_history_cb.weights_history.keys())])\n",
    "smooth.analysis.plot_shallow(_model, dataset)\n",
    "\n",
    "_model.set_weights(ow)\n",
    "smooth.analysis.plot_shallow(_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(activation, n=2, plot=False):\n",
    "    init_scales = np.logspace(np.log10(0.1), np.log10(10.), n)\n",
    "    models = dict()\n",
    "\n",
    "    for init_scale in init_scales:\n",
    "        history_cb = smooth.callbacks.WeightsHistoryCallback(min_snapshots=75)\n",
    "\n",
    "        models[init_scale] = smooth.model.train_shallow(\n",
    "            dataset,\n",
    "            learning_rate=0.01 / init_scale,\n",
    "            init_scale=init_scale,\n",
    "            epochs=30000,\n",
    "            hidden_size=400,\n",
    "            batch_size=len(dataset.x_train),\n",
    "            verbose=0,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\"loss\", min_delta=1e-5, patience=2000),\n",
    "                smooth.callbacks.Tqdm(verbose=0),\n",
    "                tf.keras.callbacks.TerminateOnNaN(),\n",
    "                history_cb\n",
    "            ],\n",
    "            train_val_split=1.0,\n",
    "            activation=activation,\n",
    "        )\n",
    "\n",
    "        if plot:\n",
    "            smooth.analysis.plot_shallow(models[init_scale], dataset)\n",
    "            ani = smooth.analysis.plot_shallow(\n",
    "                models[init_scale],\n",
    "                dataset,\n",
    "                weights_history=history_cb.weights_history,\n",
    "            )\n",
    "            display(HTML(ani.to_html5_video()))\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_relu = train_models(\"relu\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tanh = train_models(\"tanh\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measures(models):\n",
    "    measures = dict()\n",
    "\n",
    "    for init_scale, model in tqdm.notebook.tqdm(models.items()):\n",
    "        measures[init_scale] = smooth.measures.get_measures(model, x_test, y_test)\n",
    "\n",
    "    measure_names = measures[init_scales[0]].keys()\n",
    "\n",
    "    x = sorted(measures.keys())\n",
    "    yd = dict(zip(measure_names,[[] for _ in range(len(measure_names))]))\n",
    "\n",
    "    for init_scale in x:\n",
    "        for k, v in measures[init_scale].items():\n",
    "            yd[k].append(v)\n",
    "\n",
    "    for measure_name in measure_names:\n",
    "        plt.plot(x, yd[measure_name])\n",
    "        plt.title(measure_name)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.show()\n",
    "    \n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measures(models_relu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measures(models_tanh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs_debug/0224-115640/\")\n",
    "df = pd.read_feather(\"measures.feather\")\n",
    "smooth.analysis.remove_constant_columns(df, verbose=True)\n",
    "df = smooth.analysis.expand_dataset_columns(df)\n",
    "df[\"log_dir\"] = df[\"log_dir\"].str.split(\"/\").str.get(-1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interpolation_measures(dataset_names, use_test_set=False):\n",
    "    res = []\n",
    "    for dataset_name in tqdm.notebook.tqdm(dataset_names):\n",
    "        dataset = smooth.datasets.GaussianProcessDataset.from_name(dataset_name)\n",
    "        model = smooth.model.interpolate_relu_network(dataset, use_test_set)\n",
    "        measures = smooth.measures.get_measures(\n",
    "            model,\n",
    "            dataset.x_test, dataset.y_test,\n",
    "            include_training_measures=False,\n",
    "        )\n",
    "        res.append(measures)\n",
    "    \n",
    "    return pd.DataFrame(res, index=dataset_names)\n",
    "\n",
    "im_train = get_interpolation_measures(df[\"dataset\"].unique())\n",
    "im_test = get_interpolation_measures(df[\"dataset\"].unique(), use_test_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_delta = im_train - im_test\n",
    "im_delta.sort_values(\"seg_total_variation_derivative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = smooth.datasets.GaussianProcessDataset.from_name(\"gp-1-0.1-10\")\n",
    "plt.plot(dataset.x_train, dataset.y_train)\n",
    "plt.plot(dataset.x_test, dataset.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df[\"dataset_seed\"] == 1) & (df[\"dataset_lengthscale\"] == 0.1) & (df[\"train_loss\"] < 10)]\n",
    "# df1 = df1[(df1[\"\"])]\n",
    "print(len(df1))\n",
    "plt.scatter(df1[\"dataset_samples_train\"], df1[\"seg_total_variation\"], alpha=0.3)\n",
    "df1 = df1[df1[\"dataset_samples_train\"] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = smooth.datasets.GaussianProcessDataset.from_name(df1.iloc[0][\"dataset\"])\n",
    "x = dataset.x_test\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.plot(x, dataset.y_test, color=\"C0\")\n",
    "\n",
    "for i, row in list(df1.iterrows()):\n",
    "    log_dir = row[\"log_dir\"]\n",
    "    model = tf.keras.models.load_model(os.path.join(log_dir, \"model.h5\"))\n",
    "    y = model.predict(x)\n",
    "    color = {\n",
    "        10: \"C1\",\n",
    "        30: \"C2\",\n",
    "        100: \"C3\",\n",
    "    }[row[\"dataset_samples_train\"]]\n",
    "    ax.plot(x, y, alpha=0.3, color=color)\n",
    "\n",
    "\n",
    "#     smooth.analysis.plot_shallow(model, dataset, title=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "ax = plt.subplot()\n",
    "ax.plot(df1[\"train_loss\"], df1[\"test_loss\"], marker='o', linestyle=\"None\")\n",
    "# ax.set_xlim(auto=True)\n",
    "# df1[\"train_loss\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df1[\"train_loss\"], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        continue\n",
    "    plt.hist(df[col], bins=20)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"dataset\"].str.match(\"gp-.*-0.1-30$\")]\n",
    "\n",
    "for i, row in df1.sort_values(\"train_loss\").iterrows():\n",
    "    log_dir = row[\"log_dir\"]\n",
    "    model = tf.keras.models.load_model(os.path.join(log_dir, \"model.h5\"))\n",
    "    dataset = smooth.datasets.GaussianProcessDataset.from_name(row[\"dataset\"])\n",
    "    smooth.analysis.plot_shallow(model, dataset, title=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = smooth.datasets.Dataset(x_train=[-1, 0, 1, 2], y_train =[-1, 1, 0, 1], x_test=[], y_test=[])\n",
    "dataset = smooth.datasets.GaussianProcessDataset.from_name(df1.iloc[0][\"dataset\"])\n",
    "plt.plot(dataset.x_train, dataset.y_train)\n",
    "model = smooth.model.interpolate_relu_network(dataset)\n",
    "smooth.analysis.plot_shallow(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
