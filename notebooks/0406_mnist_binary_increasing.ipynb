{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothness as a function of # training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "sns.set()\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.config\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measure(ms, measure_name):\n",
    "    grid = sns.relplot(\n",
    "        data=ms,\n",
    "        x=\"dataset.samples_train\",\n",
    "        y=measure_name,\n",
    "        hue=\"model.hidden_size\",\n",
    "        palette=smooth.analysis.make_palette(ms[\"model.hidden_size\"]),\n",
    "#         kind=\"line\",\n",
    "    )\n",
    "\n",
    "    ax = grid.axes[0][0]\n",
    "    if \"loss_train\" in measure_name:\n",
    "        ax.set_yscale(\"log\")\n",
    "    ax.set_xscale(\"log\")\n",
    "#     ax.set_xlim((3, 1200))\n",
    "    plt.show()\n",
    "\n",
    "def plot_measures(ms):    \n",
    "    for measure in [\n",
    "        \"loss_train\", \"loss_test\",\n",
    "    #     \"gradient_norm_train\",\n",
    "        \"gradient_norm_test\",\n",
    "        \"weights_product\",\n",
    "        \"path_length_f_test\",\n",
    "        \"path_length_d_test\",\n",
    "    ]:\n",
    "        plot_measure(ms, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = pd.read_feather(\"./0406_mnist_binary_increasing/measures.feather\")\n",
    "smooth.analysis.remove_constant_columns(ms, verbose=True)\n",
    "\n",
    "ms.head()\n",
    "plot_measures(ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "      \"./0519_binary_increasing/measures.feather\",\n",
    "#     \"./0518_binary_increasing/measures.feather\",\n",
    "    kind_cols=[(\"dataset.samples_train\", \"samples\")],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "ms[\"model.hidden_size\"] = 256\n",
    "\n",
    "taus, ps = [\n",
    "    smooth.analysis.summarize_kendalls(\n",
    "        ms,\n",
    "        groupby=\"dataset.name\",\n",
    "        x_col=\"dataset.samples_train\",\n",
    "        y_cols=smooth.analysis.get_measure_names(),\n",
    "        get_pvalues=get_pvalues,\n",
    "    )\n",
    "    for get_pvalues in [False, True]\n",
    "]\n",
    "display(taus.describe().round(2))\n",
    "display(ps.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1 = ms[ms[\"dataset.name\"] == \"mnist28\"]\n",
    "import scipy.stats\n",
    "scipy.stats.kendalltau(ms1[\"dataset.samples_train\"], ms1[\"weights_product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.kendalltau([0, 0, 1, 1], [0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_table(col_dfs):\n",
    "    measures = [\n",
    "        (\"gradient_norm_test\", \"GN\"),\n",
    "        (\"weights_product\", \"WP\"),\n",
    "        (\"path_length_f_test\", \"PL_0\"),\n",
    "        (\"path_length_d_test\", \"PL_1\"),\n",
    "    ]\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for measure_col, measure_tex in measures:\n",
    "        row = \"${}$\".format(measure_tex).ljust(10)\n",
    "        \n",
    "        for col_df in col_dfs:\n",
    "            row += \" & ${:.2f} \\pm {:.2f}$\".format(\n",
    "                col_df.loc[\"mean\", measure_col],\n",
    "                col_df.loc[\"std\", measure_col],\n",
    "            )\n",
    "        rows.append(row)\n",
    "    \n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "format_for_table([taus.describe(), ps.describe()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in [\n",
    "    \"loss_train\", \"loss_test\",\n",
    "#     \"gradient_norm_train\",\n",
    "    \"gradient_norm_test\",\n",
    "    \"weights_product\",\n",
    "    \"path_length_f_test\",\n",
    "    \"path_length_d_test\",\n",
    "    \"actual_epochs\",\n",
    "]:\n",
    "    plot_measure(ms[ms[\"dataset.name\"] == \"mnist59\"], measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-do 2 (init scale 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "#       \"./0523_binary_increasing_is_1/measures.feather\",\n",
    "#       \"./0525_binary_increasing_is_1/measures.feather\",\n",
    "      \"./0528_binary_increasing_is_1/measures.feather\",\n",
    "    kind_cols=[(\"dataset.samples_train\", \"samples\")],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "ms[\"model.hidden_size\"] = 256\n",
    "\n",
    "taus, ps = [\n",
    "    smooth.analysis.summarize_kendalls(\n",
    "        ms,\n",
    "        groupby=\"dataset.name\",\n",
    "        x_col=\"dataset.samples_train\",\n",
    "        y_cols=smooth.analysis.get_measure_names(),\n",
    "        get_pvalues=get_pvalues,\n",
    "    )\n",
    "    for get_pvalues in [False, True]\n",
    "]\n",
    "display(taus.describe().round(2))\n",
    "display(ps.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_for_table([taus.describe()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in [\n",
    "    \"loss_train\", \"loss_test\",\n",
    "#     \"gradient_norm_train\",\n",
    "    \"gradient_norm_test\",\n",
    "    \"weights_product\",\n",
    "    \"path_length_f_test\",\n",
    "    \"path_length_d_test\",\n",
    "    \"actual_epochs\",\n",
    "]:\n",
    "    plot_measure(ms, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in [\n",
    "    \"loss_train\", \"loss_test\",\n",
    "#     \"gradient_norm_train\",\n",
    "    \"gradient_norm_test\",\n",
    "    \"weights_product\",\n",
    "    \"path_length_f_test\",\n",
    "    \"path_length_d_test\",\n",
    "    \"actual_epochs\",\n",
    "]:\n",
    "    plot_measure(ms, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
