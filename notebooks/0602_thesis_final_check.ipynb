{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "import scipy.stats\n",
    "sns.set()\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_kendalls(ms, groupby):\n",
    "    return smooth.analysis.summarize_kendalls(\n",
    "        ms,\n",
    "        groupby=groupby,\n",
    "        x_col=\"dataset.samples_train\",\n",
    "        y_cols=smooth.analysis.get_measure_names(),\n",
    "        get_pvalues=False,\n",
    "    ).describe().round(2).loc[[\"mean\", \"std\"]].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing training set size\n",
    "\n",
    "## 1-D, NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "    \"./0519_gp_1d/measures.feather\",\n",
    "    kind_cols=[\n",
    "        (\"dataset.seed\", \"seed\"),\n",
    "        (\"dataset.samples_train\", \"samples\"),\n",
    "    ],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "\n",
    "summarize_kendalls(ms, groupby=\"dataset.seed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-D, polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "    \"./0519_gp_1d/measures_polynomials.feather\",\n",
    "    kind_cols=[\n",
    "        (\"dataset.seed\", \"seed\"),\n",
    "        (\"dataset.samples_train\", \"samples\"),\n",
    "    ],\n",
    "    remove_unconverged=False,\n",
    ")\n",
    "\n",
    "summarize_kendalls(ms, groupby=\"dataset.seed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-D, init scale 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_feather(\"./0519_binary_increasing/measures.feather\").iloc[0][\"model.init_scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "      \"./0519_binary_increasing/measures.feather\",\n",
    "    kind_cols=[(\"dataset.samples_train\", \"samples\")],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "\n",
    "summarize_kendalls(ms, groupby=\"dataset.name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-D, init scale 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_feather(\"./0528_binary_increasing_is_1/measures.feather\").iloc[0][\"model.init_scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "      \"./0528_binary_increasing_is_1/measures.feather\",\n",
    "    kind_cols=[(\"dataset.samples_train\", \"samples\")],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "\n",
    "summarize_kendalls(ms, groupby=\"dataset.name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicit regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_names = [\n",
    "    \"gradient_norm_test\",\n",
    "    \"path_length_f_test\",\n",
    "    \"path_length_d_test\",\n",
    "    \"weights_product\",\n",
    "]\n",
    "\n",
    "def get_ratios(\n",
    "    ms: pd.DataFrame, base_mask: pd.DataFrame, normed_col: str, match_col=\"dataset.name\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes normalized values of a dataframe's column by dividing by the value\n",
    "    in a \"corresponding\" row. Used e.g. when explicitly regularizing smoothness measures\n",
    "    \"\"\"\n",
    "    ms = ms.copy()\n",
    "    base = ms[base_mask]\n",
    "    assert base[match_col].is_unique\n",
    "\n",
    "    normed_col_after = normed_col + \"_normalized\"\n",
    "\n",
    "    # Inefficient, but good enough\n",
    "    for _, row in base.iterrows():\n",
    "        cur = ms.loc[ms[match_col] == row[match_col]]\n",
    "        ms.loc[ms[match_col] == row[match_col], normed_col_after] = (\n",
    "            cur[normed_col] / row[normed_col]\n",
    "        )\n",
    "\n",
    "    return ms\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    index=measure_names,\n",
    "    columns=[\"Unregularized mean\", \"Regularized mean\", \"Lower bound\", \"Normalized mean\", \"Normalized std\"],\n",
    "    dtype=float,\n",
    ")\n",
    "\n",
    "summary[\"Lower bound\"] = [0., 0., 1., 0.]\n",
    "\n",
    "def update_summary(measures, measure_name, reg_coef_col_name, baseline=0):\n",
    "    if baseline == 0:\n",
    "        measure_name_normalized = measure_name + \"_normalized\"\n",
    "    else:\n",
    "        measure_name_normalized = measure_name + \"_baselined_normalized\"\n",
    "    \n",
    "    unreg_mean = measures[measures[reg_coef_col_name] == 0][measure_name].mean()\n",
    "    summary.loc[measure_name, \"Unregularized mean\"] = unreg_mean\n",
    "\n",
    "    largest_coef = max(measures[reg_coef_col_name])\n",
    "    stats = measures[measures[reg_coef_col_name] == largest_coef].describe()\n",
    "\n",
    "    summary.loc[measure_name, \"Regularized mean\"] = stats.loc[\"mean\", measure_name]\n",
    "    summary.loc[measure_name, \"Normalized mean\"] = stats.loc[\"mean\", measure_name_normalized]\n",
    "    summary.loc[measure_name, \"Normalized std\"] = stats.loc[\"std\", measure_name_normalized]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "      \"./0410_gradient_reg/measures.feather\",\n",
    "    kind_cols=[\n",
    "        (\"model.learning_rate\", \"lr\"),\n",
    "        (\"model.gradient_norm_reg_coef\", \"gn\"),\n",
    "    ],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "ms = ms.loc[ms[\"model.learning_rate\"] == 0.01]\n",
    "\n",
    "ms = smooth.analysis.get_ratios(ms, ms[\"model.gradient_norm_reg_coef\"] == 0, \"gradient_norm_test\")\n",
    "update_summary(ms, \"gradient_norm_test\", \"model.gradient_norm_reg_coef\")\n",
    "summary.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "      \"./0413_weights_product_reg/measures_both.feather\",\n",
    "    kind_cols=[\n",
    "        (\"model.learning_rate\", \"lr\"),\n",
    "        (\"model.weights_product_reg_coef\", \"wp\"),\n",
    "    ],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "ms = ms.loc[ms[\"model.learning_rate\"] == 0.01]\n",
    "\n",
    "ms = ms[ms[\"dataset.name\"].isin(\n",
    "    set(ms.loc[ms[\"model.weights_product_reg_coef\"].round(5) == 3e-5, \"dataset.name\"])\n",
    ")]\n",
    "\n",
    "ms = smooth.analysis.get_ratios(ms, ms[\"model.weights_product_reg_coef\"] == 0, \"weights_product\")\n",
    "update_summary(ms, \"weights_product\", \"model.weights_product_reg_coef\")\n",
    "summary.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "      \"./0508_path_length_f_reg/measures_both.feather\",\n",
    "    kind_cols=[\n",
    "        (\"model.learning_rate\", \"lr\"),\n",
    "        (\"model.path_length_f_reg_coef\", \"coef\"),\n",
    "    ],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "\n",
    "ms = ms.loc[ms[\"actual_epochs\"] < 25000]\n",
    "ms = ms[ms[\"dataset.name\"].isin(\n",
    "    set(ms.loc[ms[\"model.path_length_f_reg_coef\"].round(10) == 0.0001, \"dataset.name\"])\n",
    ")]\n",
    "\n",
    "ms[\"path_length_f_test_baselined\"] = ms[\"path_length_f_test\"] - 1\n",
    "ms = get_ratios(ms, ms[\"model.path_length_f_reg_coef\"] == 0, \"path_length_f_test_baselined\")\n",
    "\n",
    "update_summary(ms, \"path_length_f_test\", \"model.path_length_f_reg_coef\", baseline=1)\n",
    "summary.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = smooth.analysis.load_measures(\n",
    "      \"./0508_path_length_d_reg/measures_both.feather\",\n",
    "    kind_cols=[\n",
    "        (\"model.learning_rate\", \"lr\"),\n",
    "        (\"model.path_length_d_reg_coef\", \"coef\"),\n",
    "    ],\n",
    "    remove_unconverged=True,\n",
    ")\n",
    "\n",
    "# Only take into account the models which converged in the regularized version.\n",
    "ms = ms.loc[ms[\"actual_epochs\"] < 25000]\n",
    "ms = ms[ms[\"dataset.name\"].isin(\n",
    "    set(ms.loc[ms[\"model.path_length_d_reg_coef\"].round(10) == 0.00001, \"dataset.name\"])\n",
    ")]\n",
    "\n",
    "ms = get_ratios(ms, ms[\"model.path_length_d_reg_coef\"] == 0, \"path_length_d_test\")\n",
    "\n",
    "update_summary(ms, \"path_length_d_test\", \"model.path_length_d_reg_coef\")\n",
    "summary.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
