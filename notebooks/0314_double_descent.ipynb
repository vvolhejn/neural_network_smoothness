{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double descent on GP datasets\n",
    "\n",
    "Fixed training set size, a lot of different hidden layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "import GPy\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0314_double_descent/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = pd.read_feather(\"./measures.feather\")\n",
    "print(\"Before removal:\", len(ms))\n",
    "# ms_nn = ms_nn.loc[np.isfinite(ms_nn[\"path_length_f_test\"])]\n",
    "ms = ms.loc[ms[\"error\"].isnull()]\n",
    "print(\"After removal:\", len(ms))\n",
    "smooth.analysis.remove_constant_columns(ms, verbose=True)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./run_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measures(ms1):\n",
    "    measure_cols = [\n",
    "        \"loss_train\", \"loss_test\",\n",
    "        \"gradient_norm\",\n",
    "        \"path_length_f_test\",\n",
    "        \"path_length_d_test\",\n",
    "        \"weights_rms\",\n",
    "    ]\n",
    "\n",
    "    for measure in measure_cols:\n",
    "        IPython.display.display(IPython.display.Markdown(\"### {}\".format(measure)))\n",
    "        if True:\n",
    "    #         ms1 = ms_mean[(ms_nn[\"hidden_size\"] == 64)]\n",
    "    #         ms1 = ms_nn[(ms_nn[\"init_scale\"] == 10.)]\n",
    "            grid = sns.relplot(\n",
    "                data=ms1,\n",
    "                x=\"hidden_size\",\n",
    "                y=measure,\n",
    "                hue=\"dim\",\n",
    "    #             col_wrap=3,\n",
    "                kind=\"line\",\n",
    "                palette=smooth.analysis.make_palette(ms1[\"dim\"].unique()),\n",
    "            )\n",
    "            ax = grid.axes[0][0]\n",
    "\n",
    "            ax.set_xscale(\"log\")\n",
    "            if \"loss\" in measure or True:\n",
    "                ax.set_yscale(\"log\")\n",
    "            plt.show()\n",
    "\n",
    "plot_measures(\n",
    "    ms.loc[(ms[\"samples_train\"] == 100) & (ms[\"dim\"] == 128)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
