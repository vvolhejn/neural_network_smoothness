{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP datasets with zero noise_var + NNs (2)\n",
    "\n",
    "- on these GP datasets, the measures _do not_ increase with an increasing number of samples. But they _do_ increase on MNIST! Why is this?\n",
    "  - GP datasets are too easy?\n",
    "  - dimensionality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "import GPy\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0306_gp_nn_noiseless/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of shallow relu neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn = pd.read_feather(\"measures.feather\")\n",
    "# ms_nn = smooth.analysis.expand_dataset_columns(ms_nn)\n",
    "print(\"Before removal:\", len(ms_nn))\n",
    "# ms_nn = ms_nn.loc[np.isfinite(ms_nn[\"path_length_f_test\"])]\n",
    "ms_nn = ms_nn.loc[ms_nn[\"error\"].isnull()]\n",
    "print(\"After removal:\", len(ms_nn))\n",
    "\n",
    "ms_nn[\"lengthscale\"] = ms_nn[\"dim\"] * ms_nn[\"lengthscale_coef\"]\n",
    "# smooth.analysis.remove_constant_columns(ms_nn, verbose=True, to_keep=[\"dataset.name\", \"seed\", \"disjoint\"])\n",
    "\n",
    "ms_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_datasets(ms):\n",
    "    dataset_cols = [\"dataset.name\", \"dim\", \"seed\", \"lengthscale_coef\", \"samples_train\", \"noise_var\", \"disjoint\"]\n",
    "    datasets = ms.loc[:, dataset_cols]\n",
    "    \n",
    "    def strip(s, prefix):\n",
    "        if s.startswith(prefix):\n",
    "            return s[len(prefix):]\n",
    "        else:\n",
    "            return s\n",
    "    \n",
    "    renamed_cols = [strip(x, \"dataset.\") for x in dataset_cols]\n",
    "    renaming = dict(zip(dataset_cols, renamed_cols))\n",
    "    return (datasets\n",
    "            .rename(columns=renaming)\n",
    "            .drop_duplicates()\n",
    "            .sort_values(renamed_cols)\n",
    "            .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([smooth.analysis.get_gp_measures(\n",
    "        datasets[15:16],\n",
    "        from_params=True,\n",
    "        kernel_f=GPy.kern.Matern32,\n",
    "        lengthscale_coef=1.,\n",
    "    ),\n",
    "           smooth.analysis.get_gp_measures(\n",
    "        datasets[15:16],\n",
    "        from_params=True,\n",
    "        kernel_f=GPy.kern.Matern32,\n",
    "        lengthscale_coef=0.1,\n",
    "    ),\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(get_unique_datasets(ms_nn).to_dict(\"index\").values())\n",
    "datasets2 = get_unique_datasets(ms_nn)\n",
    "datasets2 = list(datasets2[datasets2[\"lengthscale_coef\"] == 1.0].to_dict(\"index\").values())\n",
    "\n",
    "ms_gp = smooth.analysis.compute_or_load_df(\n",
    "    lambda: smooth.analysis.get_gp_measures(datasets, from_params=True),\n",
    "    \"measures_gp.feather\",\n",
    "    always_compute=False,\n",
    ")\n",
    "\n",
    "def f():\n",
    "    l = []\n",
    "    for lsc in [0.1, 1., 10., 100.]:\n",
    "        cur = smooth.analysis.get_gp_measures(\n",
    "            datasets2,\n",
    "            from_params=True,\n",
    "            kernel_f=GPy.kern.Matern32,\n",
    "            lengthscale_coef=lsc,\n",
    "        )\n",
    "        cur[\"lengthscale_coef\"] = lsc\n",
    "        l.append(cur)\n",
    "    \n",
    "    return pd.concat(l).reset_index(drop=True)\n",
    "\n",
    "ms_gp_m32 = smooth.analysis.compute_or_load_df(\n",
    "    f,\n",
    "    \"measures_gp_matern32.feather\",\n",
    "    always_compute=True,\n",
    ")\n",
    "\n",
    "# ms_gp_m52 = smooth.analysis.compute_or_load_df(\n",
    "#     lambda: smooth.analysis.get_gp_measures(datasets, from_params=True, kernel_f=GPy.kern.Matern52),\n",
    "#     \"measures_gp_matern52.feather\",\n",
    "#     always_compute=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth.analysis.remove_constant_columns(ms_nn, verbose=True, to_keep=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_cols = [\n",
    "    \"loss_train\", \"loss_test\",\n",
    "    \"path_length_f_train\", \"path_length_f_test\",\n",
    "    \"path_length_d_train\", \"path_length_d_test\",\n",
    "    \"weights_rms\",\n",
    "]\n",
    "\n",
    "for measure in measure_cols:\n",
    "    IPython.display.display(IPython.display.Markdown(\"### {}\".format(measure)))\n",
    "    if True:\n",
    "        ms1 = ms_nn[(ms_nn[\"hidden_size\"] == 64)\n",
    "                    & (ms_nn[\"lengthscale_coef\"] == 0.3)]\n",
    "#         ms1 = ms_nn[(ms_nn[\"init_scale\"] == 10.)]\n",
    "        grid = sns.relplot(\n",
    "            data=ms1,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"init_scale\",\n",
    "#             style=\"learning_rate\",\n",
    "            col=\"dim\",\n",
    "            col_wrap=3,\n",
    "            kind=\"line\",\n",
    "            palette=smooth.analysis.make_palette(ms1[\"init_scale\"].unique()),\n",
    "        )\n",
    "        ax = grid.axes[0] #[0]\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        if \"loss\" in measure or True:\n",
    "            ax.set_yscale(\"log\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normalized_cols(ms):\n",
    "    ms[\"plc\"] = ms[\"path_length_f_test\"] / ms[\"path_length_f_test_bound\"]\n",
    "    ms[\"plct\"] = ms[\"path_length_f_train\"] / ms[\"path_length_f_train_bound\"]\n",
    "    return ms\n",
    "\n",
    "#add_normalized_cols(ms_gp)\n",
    "\n",
    "ms_bound = (ms_gp\n",
    "    .drop(columns=[\"path_length_f_test\", \"path_length_f_train\", \"loss_train\", \"loss_test\"])\n",
    "    .rename(columns={\n",
    "        \"path_length_f_test_bound\": \"path_length_f_test\",\n",
    "        \"path_length_f_train_bound\": \"path_length_f_train\",\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(groups, filter_f: None):\n",
    "    filter_f = filter_f or (lambda df: df)\n",
    "    l = []\n",
    "    for group_name, group in groups:\n",
    "        for name, ms_cur in group:\n",
    "            ms_cur = ms_cur.copy()\n",
    "            ms_cur.loc[:, \"source\"] = name\n",
    "            ms_cur.loc[:, \"group\"] = group_name\n",
    "            l.append(ms_cur)\n",
    "\n",
    "    ms_all = pd.concat(l, sort=False)\n",
    "    ms_all = filter_f(ms_all)\n",
    "    \n",
    "    for measure in [\"loss_train\", \"loss_test\", \"path_length_f_test\", \"path_length_f_train\"]:\n",
    "        grid = sns.relplot(\n",
    "            data=ms_all,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"source\",\n",
    "            style=\"group\",\n",
    "            col=\"dim\",\n",
    "            col_wrap=2,\n",
    "            kind=\"line\",\n",
    "        )\n",
    "        ax = grid.axes[0]#[0]\n",
    "        ax.set_xscale(\"log\")\n",
    "        if measure in [\"loss_train\", \"loss_test\",\n",
    "                      \"path_length_f_train\", \"path_length_f_test\",\n",
    "                      ]:\n",
    "            ax.set_yscale(\"log\")\n",
    "#         if measure in [\"path_length_f\"]:\n",
    "#             ax.set_ylim(0.03, 30)\n",
    "        plt.show()\n",
    "\n",
    "nn_group = []\n",
    "for init in sorted(ms_nn[\"init_scale\"].unique()):\n",
    "#     for lr in sorted(ms_nn[\"learning_rate\"].unique()):\n",
    "    for lr in [(0.003 / init).round(5)]:\n",
    "#     lr = (0.01 / init).round(5)\n",
    "        nn_group.append((\n",
    "            \"nn, lr={:.1e}, is={:.1e}\".format(lr, init),\n",
    "            ms_nn.loc[\n",
    "                (ms_nn[\"hidden_size\"] == 64) &\n",
    "                (ms_nn[\"init_scale\"] == init) &\n",
    "                (ms_nn[\"learning_rate\"] == lr)\n",
    "            ],\n",
    "        ))\n",
    "    break\n",
    "\n",
    "nn_group.append((\"gp\", ms_gp))\n",
    "nn_group.append((\"bound\", ms_bound))\n",
    "\n",
    "def filter_f(ms):\n",
    "    return ms.loc[\n",
    "#         (ms[\"dim\"] == dim)\n",
    "#         & (ms_all[\"seed\"] == 1)\n",
    "        (ms[\"lengthscale\"] == ms[\"dim\"])\n",
    "        & (ms[\"disjoint\"] == 1)\n",
    "#         & (ms[\"dim\"] <= 512)\n",
    "    ]\n",
    "\n",
    "for dim in sorted(ms_nn[\"dim\"].unique())[:1]:\n",
    "    display(IPython.display.Markdown(\"### dim = {}\".format(dim)))\n",
    "    plot_compare(\n",
    "        [\n",
    "            (\"nn\", nn_group),\n",
    "        ],\n",
    "        filter_f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(groups, filter_f: None):\n",
    "    filter_f = filter_f or (lambda df: df)\n",
    "    l = []\n",
    "    for group_name, group in groups:\n",
    "        for name, ms_cur in group:\n",
    "            ms_cur = ms_cur.copy()\n",
    "            ms_cur.loc[:, \"source\"] = name\n",
    "            ms_cur.loc[:, \"group\"] = group_name\n",
    "            l.append(ms_cur)\n",
    "\n",
    "    ms_all = pd.concat(l, sort=False)\n",
    "    ms_all = filter_f(ms_all)\n",
    "    \n",
    "    for measure in [\"loss_train\", \"loss_test\", \"path_length_f_test\", \"path_length_f_train\"]:\n",
    "        grid = sns.relplot(\n",
    "            data=ms_all,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"source\",\n",
    "            style=\"group\",\n",
    "            col=\"dim\",\n",
    "            col_wrap=2,\n",
    "            kind=\"line\",\n",
    "        )\n",
    "        ax = grid.axes[0]#[0]\n",
    "        ax.set_xscale(\"log\")\n",
    "        if measure in [\"loss_train\", \"loss_test\",\n",
    "                      \"path_length_f_train\", \"path_length_f_test\",\n",
    "                      ]:\n",
    "            ax.set_yscale(\"log\")\n",
    "#         if measure in [\"path_length_f\"]:\n",
    "#             ax.set_ylim(0.03, 30)\n",
    "        plt.show()\n",
    "\n",
    "nn_group = []\n",
    "for init in sorted(ms_nn[\"init_scale\"].unique()):\n",
    "#     for lr in sorted(ms_nn[\"learning_rate\"].unique()):\n",
    "    for lr in [(0.003 / init).round(5)]:\n",
    "#     lr = (0.01 / init).round(5)\n",
    "        nn_group.append((\n",
    "            \"nn, lr={:.3f}, is={:.3f}\".format(lr, init),\n",
    "            ms_nn.loc[\n",
    "                (ms_nn[\"hidden_size\"] == 256) &\n",
    "                (ms_nn[\"init_scale\"] == init) &\n",
    "                (ms_nn[\"learning_rate\"] == lr)\n",
    "            ],\n",
    "        ))\n",
    "\n",
    "nn_group.append((\"bound\", ms_bound))\n",
    "nn_group.append((\"gp\", ms_gp))\n",
    "\n",
    "gp_group = []\n",
    "for lsc in sorted(ms_gp_m32[\"lengthscale_coef\"]):\n",
    "    gp_group.append((\"gp m32, lsc={}\".format(lsc), ms_gp_m32.loc[ms_gp_m32[\"lengthscale_coef\"] == lsc]))\n",
    "\n",
    "def filter_f(ms):\n",
    "    return ms.loc[\n",
    "#         (ms[\"dim\"] == dim)\n",
    "#         & (ms_all[\"seed\"] == 1)\n",
    "        (ms[\"lengthscale\"] == ms[\"dim\"])\n",
    "        & (ms[\"disjoint\"] == 1)\n",
    "#         & (ms[\"dim\"] <= 512)\n",
    "    ]\n",
    "\n",
    "for dim in sorted(ms_nn[\"dim\"].unique())[:1]:\n",
    "    display(IPython.display.Markdown(\"### dim = {}\".format(dim)))\n",
    "    plot_compare(\n",
    "        [\n",
    "            (\"nn\", nn_group),\n",
    "            (\"gp\", gp_group),\n",
    "        ],\n",
    "        filter_f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = smooth.datasets.get_mnist()\n",
    "mnist.y_train % 2 * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    \n",
    "    class C:\n",
    "        def __init__(self, b):\n",
    "            self.val = a + b\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(3)(5).val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = smooth.datasets.MnistLightnessDataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = smooth.datasets.MnistParityDataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(ms_nn[\"hidden_size\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
