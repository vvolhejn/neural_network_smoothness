{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel ridge regression on GP datasets 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0302_gp_krr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_kr = pd.read_feather(\"measures.feather\")\n",
    "ms_kr_2 = pd.read_feather(\"measures_alpha0.feather\")\n",
    "ms_kr = pd.concat([ms_kr, ms_kr_2], ignore_index=True)\n",
    "ms_kr = smooth.analysis.expand_dataset_columns(ms_kr)\n",
    "smooth.analysis.remove_constant_columns(ms_kr, verbose=True)\n",
    "ms_kr.rename(columns={\"path_length_f_test\": \"path_length_f\"}, inplace=True)\n",
    "ms_kr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn = pd.read_feather(\"../0302-173545/measures.feather\")\n",
    "ms_nn = smooth.analysis.expand_dataset_columns(ms_nn)\n",
    "smooth.analysis.remove_constant_columns(ms_nn, verbose=True)\n",
    "ms_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = 0.1\n",
    "\n",
    "for col in ms.columns:\n",
    "    if ms[col].dtype == \"object\":\n",
    "        continue\n",
    "    \n",
    "    data = ms.loc[(ms[col] >= ms[col].quantile(trim/2)) & (ms[col] <= ms[col].quantile(1-trim/2)), col]\n",
    "    \n",
    "    plt.hist(data, bins=20)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_path_length_f(dataset_name):\n",
    "    dataset = smooth.datasets.from_name(dataset_name)\n",
    "    n = len(dataset.x_test)\n",
    "    y = sorted(dataset.y_test.reshape((-1,)))\n",
    "#     cs = np.cumsum(y)[::-1]\n",
    "#     res = 0\n",
    "#     for i in range(n - 1):\n",
    "#         res += cs[i] - y[i] * (n - i)\n",
    "\n",
    "#     return res / (n ** 2)\n",
    "    res = 0\n",
    "    for a in y:\n",
    "        for b in y:\n",
    "            res += np.abs(a - b)\n",
    "    return res / (n ** 2)\n",
    "\n",
    "\n",
    "datasets = ms[\"dataset\"].str.split(\"-\").str.slice(0, -1).str.join(\"-\").unique()\n",
    "datasets\n",
    "\n",
    "optimal_lengths = {}\n",
    "for dataset in tqdm.notebook.tqdm(datasets):\n",
    "    optimal_lengths[dataset] = get_optimal_path_length_f(\"{}-77\".format(dataset))\n",
    "\n",
    "optimal_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1 = ms\n",
    "seed = 2\n",
    "# measure_cols = [\"train_loss\", \"test_loss\", \"path_length_f_test\", \"path_length_f_train\"]\n",
    "measure_cols = [\"train_loss\", \"test_loss\", \"path_length_f\"]\n",
    "\n",
    "for dim in sorted(ms_kr[\"dim\"].unique()):\n",
    "    for measure in measure_cols:\n",
    "#         ms1 = ms_kr[(ms_kr[\"seed\"] == seed) & (ms_kr[\"dim\"] == dim) & (ms_kr[\"alpha\"] == 0.0001)]\n",
    "        ms1 = ms_kr[\n",
    "            (ms_kr[\"dim\"] == ms_kr[\"lengthscale\"])\n",
    "#             & (ms_kr[\"seed\"] == seed)\n",
    "            & (ms_kr[\"dim\"] == dim)\n",
    "            & (ms_kr[\"alpha\"] == 0.0001)\n",
    "        ]\n",
    "#         ax = plt.subplot()\n",
    "    #     ms1.loc[:,\"hidden_size_s\"] = ms1[\"hidden_size\"].astype(str) + \" units\"\n",
    "        grid = sns.relplot(\n",
    "            data=ms1,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"degree\",\n",
    "            style=\"alpha\",\n",
    "            kind=\"line\",\n",
    "    #         col=\"batch_size\",\n",
    "            palette=smooth.analysis.make_palette(ms1[\"degree\"].unique()),\n",
    "    #                 ax=ax\n",
    "        )\n",
    "        ax = grid.axes[0][0]\n",
    "#         if measure == \"test_loss\":\n",
    "#             baseline = sklearn.metrics.mean_squared_error(dataset.y_test, y_pred)\n",
    "#             plt.plot([ms_kr[\"samples_train\"].min(), ms_kr[\"samples_train\"].max()], [baseline, baseline])\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        if \"loss\" in measure:\n",
    "            ax.set_yscale(\"log\")\n",
    "        plt.title(\"dim={}\".format(dim))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth.analysis.make_palette([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(groups, dim):\n",
    "    l = []\n",
    "    for group_name, group in groups:\n",
    "        for name, ms_cur in group:\n",
    "            ms_cur.loc[:, \"source\"] = name\n",
    "            ms_cur.loc[:, \"group\"] = group_name\n",
    "            l.append(ms_cur)\n",
    "#     ms1.loc[:,\"source\"] = \"a\"\n",
    "#     ms2.loc[:,\"source\"] = \"b\"\n",
    "    ms_all = pd.concat(l, sort=False)\n",
    "    ms_all = ms_all.loc[\n",
    "        (ms_all[\"dim\"] == dim)\n",
    "        & (ms_all[\"seed\"] == 1)\n",
    "        & (ms_all[\"lengthscale\"] < ms_all[\"dim\"])\n",
    "    ]\n",
    "    \n",
    "    for measure in [\"train_loss\", \"test_loss\", \"path_length_f\"]:\n",
    "        grid = sns.relplot(\n",
    "            data=ms_all,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"source\",\n",
    "            col=\"group\",\n",
    "#             style=\"alpha\",\n",
    "        #         col=\"batch_size\",\n",
    "            kind=\"line\",\n",
    "#             palette=make_palette(ms_krr[\"degree\"].unique()),\n",
    "        #         sns.cubehelix_palette(8),\n",
    "        #                 ax=ax\n",
    "        )\n",
    "        ax = grid.axes[0][0]\n",
    "        ax.set_xscale(\"log\")\n",
    "        if measure in [\"train_loss\", \"test_loss\", \"path_length_f\"]:\n",
    "            ax.set_yscale(\"log\")\n",
    "        plt.title(\"dim={}\".format(dim))\n",
    "        plt.show()\n",
    "\n",
    "kr_group = []\n",
    "for deg in range(1, 6):\n",
    "    kr_group.append((\n",
    "        \"krr, deg={}\".format(deg),\n",
    "        ms_kr.loc[(ms_kr[\"degree\"] == deg) & (ms_kr[\"alpha\"] == 0.000)],\n",
    "    ))\n",
    "\n",
    "nn_group = []\n",
    "for hs in sorted(ms_nn[\"hidden_size\"].unique()):\n",
    "    nn_group.append((\n",
    "        \"nn, hs={:02}\".format(hs),\n",
    "        ms_nn.loc[ms_nn[\"hidden_size\"] == hs],\n",
    "    ))\n",
    "    \n",
    "# plot_compare([(\"krr\", kr_group), (\"nn\", nn_group)])\n",
    "\n",
    "for dim in sorted(ms_nn[\"dim\"].unique()):\n",
    "    plot_compare([(\"krr\", kr_group), (\"nn\", nn_group)], dim)\n",
    "\n",
    "# plot_compare({\n",
    "#     \"nn, hs=010\": ms_nn.loc[(ms_nn[\"hidden_size\"] == 32)],\n",
    "# #     \"nn, hs=030\": ms_nn.loc[(ms[\"hidden_size\"] == 30) & (ms[\"seed\"] == 1)],\n",
    "# #     \"nn, hs=100\": ms_nn.loc[(ms[\"hidden_size\"] == 100) & (ms[\"seed\"] == 1)],\n",
    "#     \"krr, deg=1\": ms_kr.loc[(ms_kr[\"degree\"] == 1) & (ms_kr[\"alpha\"] == 0.0001)],\n",
    "# #     \"krr, deg=2\": ms_kr.loc[(ms_krr[\"degree\"] == 2) & (ms_krr[\"alpha\"] == 0.0001)],\n",
    "# #     \"krr, deg=3\": ms_kr.loc[(ms_krr[\"degree\"] == 3) & (ms_krr[\"alpha\"] == 0.0001)],\n",
    "# #     \"krr, deg=4\": ms_kr.loc[(ms_krr[\"degree\"] == 4) & (ms_krr[\"alpha\"] == 0.0001)],\n",
    "# #     \"krr, deg=5\": ms_kr.loc[(ms_krr[\"degree\"] == 5) & (ms_krr[\"alpha\"] == 0.0001)],\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = smooth.datasets.from_name(\"gp-{}-{}-{}-{}\".format(64, 1, 64.0, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.kernel_ridge\n",
    "\n",
    "alpha = 1e-50\n",
    "degree = 4\n",
    "krr = sklearn.kernel_ridge.KernelRidge(\n",
    "    alpha=0,\n",
    "    kernel=\"poly\",\n",
    "    degree=degree,\n",
    "#     degree=len(dataset.x_train) + 10,\n",
    "    coef0=1,\n",
    ")\n",
    "krr.fit(dataset.x_train[:100], dataset.y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = smooth.train_kernel_models.measure_krr(krr, dataset)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A(x, deg):\n",
    "    return np.power(\n",
    "        np.tile(x, deg + 1).reshape(-1, len(x)).T,\n",
    "        range(deg + 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg\n",
    "x = np.array([0, 1.4, 2, 3])\n",
    "y = np.array([-1, 0.2, -0.9, -0.5])\n",
    "\n",
    "for deg in range(15):\n",
    "    A = get_A(x, deg)\n",
    "    p = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    x_pred = np.linspace(0, 3)\n",
    "    y_pred = np.polynomial.polynomial.polyval(x_pred, p)\n",
    "    plt.plot(x, y, 'o', label='Original data', markersize=10)\n",
    "    plt.plot(x_pred, y_pred, 'r', label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
