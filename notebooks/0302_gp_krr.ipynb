{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel ridge regression on GP datasets 2\n",
    "\n",
    "We want to show that even on n-dimensional GP datasets, kernel ridge regression with a polynomial kernel does not learn functions as smooth as neural networks do.\n",
    "\n",
    "This has proven more difficult than expected: when the KRR is not regularized and the degree is high, there is so much numerical instability that we cannot even get low training error. But when we regularize or decrease the degree, the functions _are_ smooth, often even smoother (as measured by `path_length_f`) than the original GP.\n",
    "\n",
    "This notebook contains:\n",
    "\n",
    "- comparison of measures between KRR and NNs, normalized by GP ground truth\n",
    "- in-notebook experiments with polynomials of higher degree (10 to 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0302_gp_krr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_kr = pd.read_feather(\"measures.feather\")\n",
    "ms_kr_2 = pd.read_feather(\"measures_alpha0.feather\")\n",
    "ms_kr_3 = pd.read_feather(\"measures_gamma1.feather\")\n",
    "ms_kr = pd.concat([ms_kr, ms_kr_2, ms_kr_3], ignore_index=True)\n",
    "ms_kr = smooth.analysis.expand_dataset_columns(ms_kr)\n",
    "smooth.analysis.remove_constant_columns(ms_kr, verbose=True)\n",
    "ms_kr.rename(columns={\"path_length_f_test\": \"path_length_f\"}, inplace=True)\n",
    "ms_kr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of shallow relu neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_nn = pd.read_feather(\"../0302_gp_nn/measures.feather\")\n",
    "ms_nn_64 = pd.read_feather(\"../0303_gp_nn/measures.feather\")\n",
    "\n",
    "ms_nn = pd.concat([ms_nn, ms_nn_64], sort=False)\n",
    "ms_nn = smooth.analysis.expand_dataset_columns(ms_nn)\n",
    "\n",
    "smooth.analysis.remove_constant_columns(ms_nn, verbose=True)\n",
    "print(len(ms_nn))\n",
    "ms_nn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of the original GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp = pd.read_feather(\"measures_gp.feather\")\n",
    "ms_gp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized measures - divided by the corresponding measure of GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df1, df2, join_col, cols):\n",
    "    assert set(cols + [join_col]).issubset(set(df1.columns))\n",
    "    df = pd.merge(df1, df2[cols + [join_col]], on=join_col, suffixes=(\"\", \"_0\"))\n",
    "    for col in cols:\n",
    "        df[col + \"_n\"] = df[col] / df[col + \"_0\"]\n",
    "        del df[col + \"_0\"]\n",
    "    return df\n",
    "\n",
    "measure_cols = [\"train_loss\", \"test_loss\", \"path_length_f\"]\n",
    "ms_kr = normalize(ms_kr, ms_gp, \"dataset\", measure_cols)\n",
    "ms_nn = normalize(ms_nn, ms_gp, \"dataset\", measure_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison plots\n",
    "\n",
    "Note that the data is normalized by the GP measures. Also, it is aggregated along three different seeds; the results seem to be fairly consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(groups, filter_f: None):\n",
    "    filter_f = filter_f or (lambda df: df)\n",
    "    l = []\n",
    "    for group_name, group in groups:\n",
    "        for name, ms_cur in group:\n",
    "            ms_cur = ms_cur.copy()\n",
    "            ms_cur.loc[:, \"source\"] = name\n",
    "            ms_cur.loc[:, \"group\"] = group_name\n",
    "            l.append(ms_cur)\n",
    "\n",
    "    ms_all = pd.concat(l, sort=False)\n",
    "    ms_all = filter_f(ms_all)\n",
    "    ms_all = ms_all.loc[\n",
    "        (ms_all[\"dim\"] == dim)\n",
    "#         & (ms_all[\"seed\"] == 1)\n",
    "        & (ms_all[\"lengthscale\"] == ms_all[\"dim\"])\n",
    "    ]\n",
    "    \n",
    "    for measure in [\"train_loss_n\", \"test_loss_n\", \"path_length_f_n\"]:\n",
    "        grid = sns.relplot(\n",
    "            data=ms_all,\n",
    "            x=\"samples_train\",\n",
    "            y=measure,\n",
    "            hue=\"source\",\n",
    "            col=\"group\",\n",
    "            kind=\"line\",\n",
    "        )\n",
    "        ax = grid.axes[0][0]\n",
    "        ax.set_xscale(\"log\")\n",
    "        if measure in [\"train_loss_n\", \"test_loss_n\",\n",
    "                      \"path_length_f_n\"\n",
    "                      ]:\n",
    "            ax.set_yscale(\"log\")\n",
    "        if measure in [\"path_length_f_n\"]:\n",
    "            ax.set_ylim(0.03, 30)\n",
    "        plt.show()\n",
    "\n",
    "kr_group = []\n",
    "for deg in range(1, 6):\n",
    "    kr_group.append((\n",
    "        \"krr, deg={}\".format(deg),\n",
    "        ms_kr.loc[(ms_kr[\"degree\"] == deg) & (ms_kr[\"alpha\"] == 0.000) & (ms_kr[\"gamma\"] == 1.)],\n",
    "#         ms_kr.loc[(ms_kr[\"degree\"] == deg) & (ms_kr[\"alpha\"] == 0.000)],\n",
    "    ))\n",
    "# kr_group.append((\"gp\", ms_gp))\n",
    "\n",
    "nn_group = []\n",
    "for hs in sorted(ms_nn[\"hidden_size\"].unique()):\n",
    "    nn_group.append((\n",
    "        \"nn, hs={:02}\".format(hs),\n",
    "        ms_nn.loc[ms_nn[\"hidden_size\"] == hs],\n",
    "    ))\n",
    "# nn_group.append((\"gp_nn\", ms_gp))\n",
    "\n",
    "def filter_f(ms):\n",
    "    return ms.loc[\n",
    "        (ms[\"dim\"] == dim)\n",
    "#         & (ms_all[\"seed\"] == 1)\n",
    "        & (ms[\"lengthscale\"] == ms[\"dim\"])\n",
    "    ]\n",
    "\n",
    "for dim in sorted(ms_nn[\"dim\"].unique()):\n",
    "    display(IPython.display.Markdown(\"### dim = {}\".format(dim)))\n",
    "    plot_compare([(\"krr\", kr_group), (\"nn\", nn_group)], filter_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing ground truth measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./measures_gp.feather\"\n",
    "if os.path.isfile(path):\n",
    "    raise FileExistsError(\"We have already computed this\")\n",
    "\n",
    "ms_all = pd.concat([ms_kr, ms_gp], sort=False)\n",
    "ms_gp_l = []\n",
    "\n",
    "for dim in tqdm.notebook.tqdm(sorted(ms_all[\"dim\"].unique())):\n",
    "    for seed in tqdm.notebook.tqdm(sorted(ms_all[\"seed\"].unique()), leave=False):\n",
    "        for lengthscale_coef in tqdm.notebook.tqdm([0.3, 1.0], leave=False):\n",
    "            lengthscale = float(dim) * lengthscale_coef\n",
    "            dataset0 = smooth.datasets.from_name(\"gp-{}-{}-{}-1000\".format(dim, seed, lengthscale))\n",
    "            for samples in tqdm.notebook.tqdm(sorted(ms_all[\"samples_train\"].unique()), leave=False):\n",
    "                dataset0.gp_model.set_XY(dataset0.x_train[:samples], dataset0.y_train[:samples])\n",
    "                model = smooth.measures.GPModel(dataset0.gp_model)\n",
    "                m = smooth.measures.get_measures_no_gradient(model, dataset0.subset(samples, keep_test_set=True))\n",
    "                m.update(\n",
    "                    dim=dim,\n",
    "                    seed=seed,\n",
    "                    samples_train=samples,\n",
    "                    lengthscale=lengthscale,\n",
    "                )\n",
    "                ms_gp_l.append(m)\n",
    "\n",
    "ms_gp = pd.DataFrame()\n",
    "ms_gp[\"dataset\"] = (\"gp-\" + ms_gp[\"dim\"].map(str)\n",
    "                    + \"-\" + ms_gp[\"seed\"].map(str)\n",
    "                    + \"-\" + ms_gp[\"lengthscale\"].map(str)\n",
    "                    + \"-\" + ms_gp[\"samples_train\"].map(str)\n",
    "                   )\n",
    "ms_gp.to_feather(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-degree polynomials\n",
    "\n",
    "How do the results change when we use high-degree polynomials (degree 10, 20, 30, 40, 50)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp = pd.DataFrame(ms_gp_l[40:])\n",
    "ms_gp[\"dataset\"] = (\"gp-\" + ms_gp[\"dim\"].map(str)\n",
    "                    + \"-\" + ms_gp[\"seed\"].map(str)\n",
    "                    + \"-\" + ms_gp[\"lengthscale\"].map(str)\n",
    "                    + \"-\" + ms_gp[\"samples_train\"].map(str)\n",
    "                   )\n",
    "ms_gp.to_feather(\"measures_gp.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = \"./measures_high_degree.feather\"\n",
    "if os.path.isfile(path):\n",
    "    raise FileExistsError(\"We have already computed this\")\n",
    "\n",
    "import sklearn.kernel_ridge\n",
    "import warnings\n",
    "\n",
    "ms_krr_l = []\n",
    "\n",
    "samples_l = np.logspace(np.log10(10), np.log10(1000), 10).round().astype(int)\n",
    "seed = 1\n",
    "\n",
    "for dim in tqdm.notebook.tqdm([2, 8, 32, 128], desc=\"dim\"):\n",
    "    for alpha in tqdm.notebook.tqdm([1., 0.], leave=False, desc=\"alpha\"):\n",
    "        for gamma in tqdm.notebook.tqdm([1., None], leave=False, desc=\"gamma\"):\n",
    "            lengthscale = float(dim)\n",
    "            dataset0 = smooth.datasets.from_name(\"gp-{}-{}-{}-1000\".format(dim, seed, lengthscale))\n",
    "            for degree in tqdm.notebook.tqdm([10, 20, 30, 40, 50], leave=False, desc=\"degree\"):\n",
    "                for samples in tqdm.notebook.tqdm(samples_l, leave=False, desc=\"samples\"):\n",
    "                    krr = sklearn.kernel_ridge.KernelRidge(\n",
    "                        alpha=alpha,\n",
    "                        kernel=\"poly\",\n",
    "                        degree=degree,\n",
    "                        coef0=1,\n",
    "                        gamma=gamma,\n",
    "                    )\n",
    "                    dataset = dataset0.subset(samples, keep_test_set=True)\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        try:\n",
    "                            krr.fit(dataset.x_train, dataset.y_train)\n",
    "                            m = smooth.train_kernel_models.measure_krr(krr, dataset)\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "                    m.update(\n",
    "                        dim=dim,\n",
    "                        seed=seed,\n",
    "                        alpha=alpha,\n",
    "                        gamma=gamma,\n",
    "                        degree=degree,\n",
    "                        samples_train=samples,\n",
    "                        lengthscale=lengthscale,\n",
    "                    )\n",
    "                    ms_krr_l.append(m)\n",
    "                #     y_pred = krr.predict(dataset.x_test)\n",
    "                #     break\n",
    "\n",
    "pd.DataFrame(ms_krr_l).to_feather(\"measures_high_degree.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp = pd.read_feather(\"measures_gp.feather\")\n",
    "len(ms_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-truth measures - the GP is the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp_l = []\n",
    "for dim in tqdm.notebook.tqdm([2, 8, 32, 128], desc=\"dim\"):\n",
    "    lengthscale = float(dim)\n",
    "    dataset0 = smooth.datasets.from_name(\"gp-{}-{}-{}-1000\".format(dim, seed, lengthscale))\n",
    "    for samples in tqdm.notebook.tqdm(samples_l, leave=False, desc=\"samples\"):\n",
    "        dataset0.gp_model.set_XY(dataset0.x_train[:samples], dataset0.y_train[:samples])\n",
    "        model = smooth.measures.GPModel(dataset0.gp_model)\n",
    "        m = smooth.measures.get_measures_no_gradient(model, dataset0.subset(samples, keep_test_set=True))\n",
    "        m.update(\n",
    "            dim=dim,\n",
    "            seed=seed,\n",
    "            samples_train=samples,\n",
    "            lengthscale=lengthscale,\n",
    "        )\n",
    "        ms_gp_l.append(m)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gp = pd.DataFrame(ms_gp_l)\n",
    "\n",
    "for measure in [\"path_length_f\", \"path_length_f_train\"]:\n",
    "    grid = sns.relplot(\n",
    "        data=ms_gp,\n",
    "        x=\"samples_train\",\n",
    "        y=measure,\n",
    "        col=\"dim\",\n",
    "        kind=\"line\",\n",
    "    )\n",
    "\n",
    "    ax = grid.axes[0][0]\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-degree polynomials vs GP baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_krr = pd.DataFrame(ms_krr_l)\n",
    "ms_krr.rename(columns={\"path_length_f_test\": \"path_length_f\"}, inplace=True)\n",
    "ms_krr = ms_krr.loc[(ms_krr[\"gamma\"] == 1) & (ms_krr[\"dim\"] > 0)]\n",
    "\n",
    "ms_gp[\"degree\"] = 0\n",
    "ms_gp[\"alpha\"] = 0\n",
    "\n",
    "for measure in [\"train_loss\", \"test_loss\", \"path_length_f\", \"path_length_f_train\"]:\n",
    "    ms_cur = pd.concat([ms_krr, ms_gp], sort=False)\n",
    "    grid = sns.relplot(\n",
    "        data=ms_cur,\n",
    "        x=\"samples_train\",\n",
    "        y=measure,\n",
    "        hue=\"degree\",\n",
    "        style=\"alpha\",\n",
    "        col=\"dim\",\n",
    "        kind=\"line\",\n",
    "        col_wrap=2,\n",
    "        palette=smooth.analysis.make_palette(ms_cur[\"degree\"].unique()),\n",
    "    )\n",
    "    ax = grid.axes[0]\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
