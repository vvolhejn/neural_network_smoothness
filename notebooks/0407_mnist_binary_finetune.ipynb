{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoother models through changing hyperparameters\n",
    "\n",
    "What happens to smoothness if we train models with different hyperparams? Specifically, we might try to decrease the init scale as this has yielded smoother models in the past. This is an updated version of this experiment to see how this interacts with explicit regularization. Can we get smoother models just by varying the hyperparameters?\n",
    "\n",
    "Best models:\n",
    "\n",
    "- init scale = 0.01\n",
    "- LR = 0.1 or 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "sns.set()\n",
    "\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.config\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_measures(path):\n",
    "    ms = pd.read_feather(path)\n",
    "\n",
    "    bad_mask = ~np.isfinite(ms[\"loss_test\"])\n",
    "    print(\"Removing {} entries\".format(sum(bad_mask)))\n",
    "    ms = ms[~bad_mask]\n",
    "\n",
    "    max_epochs = ms[\"model.epochs\"].iloc[0]\n",
    "    unconverged_mask = ms[\"actual_epochs\"] == max_epochs\n",
    "    print(\"Removing {} models which have not converged\".format(sum(unconverged_mask)))\n",
    "    ms = ms[~unconverged_mask]\n",
    "\n",
    "    smooth.analysis.remove_constant_columns(ms, verbose=True)\n",
    "\n",
    "    ms[\"kind\"] = \"LR: \" + ms[\"model.learning_rate\"].map(str) + \", IS: \" + ms[\"model.init_scale\"].map(str)\n",
    "    ms = ms.sort_values(\"kind\")\n",
    "\n",
    "    print(\"Remaining:\", len(ms))\n",
    "\n",
    "    return ms\n",
    "\n",
    "def should_plot_as_log(measure_name):\n",
    "    patterns = [\"loss\", \"weights_product\"]\n",
    "    \n",
    "    for p in patterns:\n",
    "        if p in measure_name:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def plot_measure(ms, measure_name):\n",
    "    ms = ms.copy()\n",
    "    if should_plot_as_log(measure_name):\n",
    "        log_measure_name = \"log10_{}\".format(measure_name)\n",
    "        ms[log_measure_name] = np.log10(ms[measure_name])\n",
    "        measure_name = log_measure_name\n",
    "\n",
    "    sns.boxplot(data=ms, x=measure_name, y=\"kind\")\n",
    "    sns.swarmplot(data=ms, x=measure_name, y=\"kind\",\n",
    "                  size=2, color=\".3\", linewidth=0\n",
    "                 )\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_all_measures(ms):\n",
    "    for g_id, g in ms.groupby(\"kind\"):\n",
    "        print(g_id, g.count().iloc[0])\n",
    "\n",
    "    for measure in [\n",
    "                \"loss_train\", \"loss_test\",\n",
    "                \"gradient_norm_test\",\n",
    "                \"weights_product\",\n",
    "                \"path_length_f_test\",\n",
    "                \"path_length_d_test\",\n",
    "                \"actual_epochs\",\n",
    "            ]:\n",
    "        plot_measure(ms, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = load_measures(\"./0407_finetune/measures.feather\")\n",
    "plot_all_measures(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = load_measures(\"./0408-170502/measures.feather\")\n",
    "plot_all_measures(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = load_measures(\"./0409-113610/measures.feather\")\n",
    "plot_all_measures(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = smooth.datasets.from_params(\"mnist12\")\n",
    "model = smooth.model.train_shallow(\n",
    "    dataset,\n",
    "    learning_rate=0.01,\n",
    "    init_scale=0.01,\n",
    "    hidden_size=256,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smooth.model.train_shallow(\n",
    "    dataset,\n",
    "    learning_rate=0.01,\n",
    "    init_scale=0.01,\n",
    "    hidden_size=256,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    gradient_norm_reg_coef=1e-2,\n",
    "    error_threshold=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smooth.model.train_shallow(\n",
    "    dataset,\n",
    "    learning_rate=0.01,\n",
    "    init_scale=0.01,\n",
    "    hidden_size=256,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    gradient_norm_reg_coef=1e-2,\n",
    "    error_threshold=0.06,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(1, weights=[np.array([[2], [1]]), np.array([0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer(np.array([[3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth.measures.gradient_norm(layer, np.array([[3., 4.]], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
