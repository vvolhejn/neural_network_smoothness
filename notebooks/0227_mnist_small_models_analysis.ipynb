{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures on MNIST - small models\n",
    "\n",
    "These models have small hidden sizes and so we might be able to observe the double descent risk curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')\n",
    "\n",
    "sys.path.append(\"/nfs/scistore12/chlgrp/vvolhejn/smooth\")\n",
    "\n",
    "# os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0226_mnist/\")\n",
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/0227_mnist_small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_raw = pd.read_feather(\"measures.feather\")\n",
    "\n",
    "ms_raw = smooth.analysis.expand_dataset_columns(ms_raw)\n",
    "ms = ms_raw\n",
    "\n",
    "print(\"Remaining:\", len(ms))\n",
    "smooth.analysis.remove_constant_columns(ms, verbose=True)\n",
    "# ms = smooth.analysis.expand_dataset_columns(ms)\n",
    "ms.loc[:,\"log_dir\"] = ms[\"log_dir\"].str.split(\"/\").str.get(-1)\n",
    "\n",
    "ms = ms.rename(columns={\n",
    "    \"seg_total_variation\": \"path_length_f\",\n",
    "    \"seg_total_variation_derivative\": \"path_length_d\",\n",
    "})\n",
    "\n",
    "ms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2 = pd.read_feather(\"measures2.feather\")\n",
    "ms2[\"log_dir\"] = ms2[\"model_path\"].str.split(\"/\").str.get(2)\n",
    "del ms2[\"model_path\"]\n",
    "# for col in [\"l2\", \"gradient_norm\", \"seg_total_variation\", \"seg_total_variation_derivative\",\n",
    "#            \"test_accuracy\", \"test_loss\"]:\n",
    "#     del ms[col]\n",
    "\n",
    "ms = pd.merge(ms, ms2[[\"log_dir\", \"path_length_f_softmax\", \"path_length_d_softmax\"]], on=\"log_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"actual_epochs\", \"train_loss\", \"test_loss\"]\n",
    "cols = ms.columns\n",
    "\n",
    "trim = 0.1\n",
    "\n",
    "for col in cols:\n",
    "    if ms[col].dtype == \"object\":\n",
    "        continue\n",
    "    \n",
    "    data = ms.loc[(ms[col] >= ms[col].quantile(trim/2)) & (ms[col] <= ms[col].quantile(1-trim/2)), col]\n",
    "    \n",
    "    plt.hist(data, bins=20)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1 = ms.sort_values(\"samples_train\")\n",
    "groups = ms1.groupby([\"hidden_size\", \"iteration\"])\n",
    "\n",
    "measure_cols = [\"gradient_norm\",\n",
    "                \"path_length_f\", \"path_length_f_softmax\",\n",
    "                \"path_length_d\", \"path_length_d_softmax\",\n",
    "               ]\n",
    "ratios = groups.agg(lambda g: np.log10(g.iloc[0] / g.iloc[-1]))[measure_cols]\n",
    "\n",
    "ratios.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1 = ms[(ms[\"hidden_size\"] == 100) & (ms[\"batch_size\"] == 128)]\n",
    "# ms1 = ms.loc[(ms[\"batch_size\"] == 256)]\n",
    "# ms1 = ms.loc[(ms[\"hidden_size\"].isin([2, 4, 8, 16]))]\n",
    "ms1 = ms\n",
    "\n",
    "\n",
    "for measure in measure_cols + [\"train_accuracy\", \"test_accuracy\", \"train_loss\", \"test_loss\", \"l2\"]:\n",
    "#     ax = plt.subplot()\n",
    "    ms1.loc[:,\"hidden_size_s\"] = ms1[\"hidden_size\"].astype(str) + \" units\"\n",
    "#     palette = sns.color_palette(\"Blues_d\", 6)\n",
    "    grid = sns.relplot(\n",
    "        data=ms1,\n",
    "        x=\"samples_train\",\n",
    "        y=measure,\n",
    "        hue=\"hidden_size\",\n",
    "        palette=smooth.analysis.make_palette(ms1[\"hidden_size\"]),\n",
    "#         hue_norm=matplotlib.colors.LogNorm(),\n",
    "        kind=\"line\",\n",
    "    )\n",
    "    ax = grid.axes[0][0]\n",
    "    ax.set_xscale(\"log\")\n",
    "    if measure in [\"train_loss\", \"test_loss\"]:\n",
    "#         print(\"ya\")\n",
    "        ax.set_yscale(\"log\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mnist = smooth.datasets.get_mnist()\n",
    "mss = ms[(ms[\"hidden_size\"] == 10) & (ms[\"batch_size\"] == 128)\n",
    "#          & (ms[\"iteration\"] == 1)\n",
    "        ]\n",
    "ms2_dict = {}\n",
    "for i, row in tqdm.notebook.tqdm(list(mss.iterrows())):\n",
    "    model = tf.keras.models.load_model(os.path.join(row[\"log_dir\"], \"model.h5\"))\n",
    "    measures = smooth.measures.get_measures(\n",
    "        model,\n",
    "        mnist.x_test, mnist.y_test,\n",
    "        include_training_measures=False,\n",
    "        is_classification=True,\n",
    "        samples=100,\n",
    "    )\n",
    "    ms2_dict[i] = measures\n",
    "# measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2[\"samples_train\"] = ms[\"samples_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
