{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST regression\n",
    "\n",
    "For GP regression datasets, I was unsuccessful in demonstrating that path length/other measures increase as a function of training set size.\n",
    "\n",
    "This is to see whether the effect can be observed in regression tasks based on MNIST. If so, then the effect (or lack thereof) can be attributed to differences between the artificial dataset and \"real\" datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# If we don't need CUDA, do this before importing TF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "import GPy\n",
    "sns.set()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices([gpus[1]], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport smooth.datasets\n",
    "%aimport smooth.model\n",
    "%aimport smooth.analysis\n",
    "%aimport smooth.callbacks\n",
    "%aimport smooth.measures\n",
    "%aimport smooth.util\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/nfs/scistore12/chlgrp/vvolhejn/smooth/logs/\")\n",
    "\n",
    "ms_mean = pd.read_feather(\"./0315_mnistmean/measures.feather\")\n",
    "smooth.analysis.remove_constant_columns(ms_mean, verbose=True, to_keep=[\"dataset.name\"])\n",
    "ms_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_parity = pd.read_feather(\"./0315_mnistparity/measures.feather\")\n",
    "ms_parity_2 = pd.read_feather(\"./0316-134648/measures.feather\")\n",
    "ms_parity = pd.concat([ms_parity, ms_parity_2])\n",
    "# smooth.analysis.remove_constant_columns(ms_parity, verbose=True, to_keep=[\"dataset.name\"])\n",
    "ms_parity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_parity[ms_parity[\"model.hidden_size\"] == 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_cols = [\n",
    "    \"loss_train\", \"loss_test\",\n",
    "    \"gradient_norm\",\n",
    "    \"path_length_f_test\",\n",
    "    \"path_length_d_test\",\n",
    "    \"weights_rms\",\n",
    "]\n",
    "\n",
    "def plot_measures(ms1):\n",
    "\n",
    "    for measure in measure_cols:\n",
    "        IPython.display.display(IPython.display.Markdown(\"### {}\".format(measure)))\n",
    "        if True:\n",
    "    #         ms1 = ms_mean[(ms_nn[\"hidden_size\"] == 64)]\n",
    "    #         ms1 = ms_nn[(ms_nn[\"init_scale\"] == 10.)]\n",
    "            grid = sns.relplot(\n",
    "                data=ms1,\n",
    "                x=\"dataset.samples_train\",\n",
    "                y=measure,\n",
    "                hue=\"model.hidden_size\",\n",
    "                col=\"dataset.name\",\n",
    "    #             col_wrap=3,\n",
    "                kind=\"line\",\n",
    "                palette=smooth.analysis.make_palette(ms1[\"model.hidden_size\"].unique()),\n",
    "            )\n",
    "            ax = grid.axes[0][0]\n",
    "\n",
    "            ax.set_xscale(\"log\")\n",
    "#             if \"loss\" in measure or True:\n",
    "#                 ax.set_yscale(\"log\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measures(pd.concat([ms_parity]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Initialization scale results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_is = pd.read_feather(\"./0317-095916/measures.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in measure_cols:\n",
    "    IPython.display.display(IPython.display.Markdown(\"### {}\".format(measure)))\n",
    "    if True:\n",
    "#         ms1 = ms_mean[(ms_nn[\"hidden_size\"] == 64)]\n",
    "#         ms1 = ms_nn[(ms_nn[\"init_scale\"] == 10.)]\n",
    "        grid = sns.relplot(\n",
    "            data=ms_is,\n",
    "            x=\"model.init_scale\",\n",
    "            y=measure,\n",
    "            kind=\"line\",\n",
    "        )\n",
    "        ax = grid.axes[0][0]\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        if \"loss\" in measure or True:\n",
    "            ax.set_yscale(\"log\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
